{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  Fine-tuning of a GPT-2 Text-Generating Model on GPU\n",
    "## using the [_aitextgen_](https://github.com/minimaxir/aitextgen) library (v0.5.2) by Max Woolf\n",
    "(This Notebook is adapted from an [original](https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD?usp=sharing) by the same author.)\n",
    "\n",
    "\n",
    "<b>NOTE</b>: If you want to use this Notebook, `copy it to your Google Drive`, `open it in Google Colaboratory` and `run the cells below`.\n"
   ],
   "metadata": {
    "id": "H7LoMj4GA4n_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 1\n",
    "\n",
    "!pip uninstall tensorboard \n",
    "!pip install tensorboard==2.3.0\n",
    "!pip install PyYAML==5.4.1"
   ],
   "outputs": [],
   "metadata": {
    "id": "1BHJzlaobHGd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 2\n",
    "\n",
    "!pip install -q aitextgen\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "from aitextgen import aitextgen\n",
    "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive"
   ],
   "outputs": [],
   "metadata": {
    "id": "KBkpRgBCBS2_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <b>The advantage of using Gooogle Colaboratory is that it provides a GPU</b> (usually an Nvidia P4, an Nvidia T4, an Nvidia P100, or an Nvidia V100).\n",
    "\n",
    "To finetune a GPT-2 124M for text generation purposes, T4 and P100 are the best choices since they have more VRAM, which will allow zou to **enable `fp16=True` during training for faster/more memory efficient training.**\n",
    "\n",
    "To verify which GPU is active,  run the cell below. To obtain a different GPU, go to **Runtime -> Factory Reset Runtime**."
   ],
   "metadata": {
    "id": "Bj2IJLHP3KwE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 3\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "#NB: Here I assume you chose to use Google Colaboratory. This cell won't work if this Notebook is run outside the ColabVM.  "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1628843897568,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "sUmTooTW3osf",
    "outputId": "a3bbb9d1-718c-43fd-8bb1-a74fe9796f19"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the GPT-2\n",
    "\n",
    "First of all, you need to download the GPT-2 model into the GPU. \n",
    "\n",
    "There are several sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M` (default): the \"medium\" model, 1.5GB on disk.\n",
    "* `774M` (default): the \"large\" model, 3GB on disk.\n",
    "\n",
    "For the <i>Karl Marx's Press Review</i> project, I used the small model, as after the fine-tuning on Google Colaboratory my laptop's humble CPU can handle that one better and faster for text generation. Users with more powerful computers may be more ambitious!\n",
    "\n",
    "The next cell downloads the model and saves it in the Colaboratory VM. If the model has already been downloaded, running this cell will reload it."
   ],
   "metadata": {
    "id": "trRhgNvsH4Wn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 4\n",
    "ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "flqSlHjMIeIw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mounting Google Drive\n",
    "\n",
    "As the author of _aitextgen_ suggests, “the best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*”.\n",
    "\n",
    "Here I again assume you chose to use Colab, as this cell will only work in that environment. This code can be used to **mount your personal Google Drive in the VM**, which later cells can use to get data in/out. \n",
    "\n",
    "**NB:** You will be asked for an authorisation code! "
   ],
   "metadata": {
    "id": "N8KXuKWzQSsN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 4\n",
    "\n",
    "mount_gdrive()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34600,
     "status": "ok",
     "timestamp": 1628844765421,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "puq4iC6vUAHc",
    "outputId": "273fdb86-3cf5-4aaf-b604-b1c09177c317"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uploading a .txt file containing the training dataset from your local machine to Colaboratory.\n",
    "#### (Also works with single-column CSV files) \n",
    "\n",
    "\n",
    "\n",
    "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
    "\n",
    "![alt text](https://i.imgur.com/w3wvHhR.png)\n",
    "\n",
    "### OPTION 1:\n",
    "If your text file is **small**, upload it in Colaboratory directly from zour local machine, update the file name in the cell below, then run the cell.\n",
    "\n",
    "**NB**: Keep in mind that the GPT2 has a limit of 1024 characters per text sample, so make sure you clean your dataset accordingly. If you are repeating my exercise on the Marx-Engels dataset, this is the time to run the Python module `scraper_preprocesser.py` that may be found in the folder `data_and_model` (check out the requirements first). This will produce a `marx.txt` file, which is already optimised to be used for the fine-tuning."
   ],
   "metadata": {
    "id": "BT__brhBCvJu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 5 \n",
    "\n",
    "file_name = \"marx.txt\""
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1628845343739,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "6OFnPCLADfll"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 6\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1628845366995,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "dJSbHs0NT_lu",
    "outputId": "64ea2d46-50be-4ab1-ebcd-f36d5edd1f92"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OPTION 2: \n",
    "If your text file is **large (>10MB**), do not upload it from your machine! Instead, **load that file to Google Drive first**, then copy that file from Google Drive to the Colaboratory VM.\n",
    "\n",
    "(As an alternative, _aitextgen_ also implements a function to [compress your dataset to a cache](https://docs.aitextgen.io/dataset/) on your local computer. At that point you can upload the resulting `dataset_cache.tar.gz` to Colab and set the `file_name`in `cell 5` to that.)"
   ],
   "metadata": {
    "id": "HeeSKtNWUedE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 7\n",
    "\n",
    "copy_file_from_gdrive(file_name)"
   ],
   "outputs": [],
   "metadata": {
    "id": "-Z6okFD8VKtS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finetune the GPT-2\n",
    "\n",
    "As Max Woolf explains in his original Notebook, the next cell will “start the actual finetuning of GPT-2 in _aitextgen_. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory). The model will be saved every `save_every` steps in `trained_model` by default, and when training completes.”\n",
    "\n",
    "**NB**: If you mounted your Google Drive (and you have done it, haven't you?...the process may be long or time out after some hours..._you definitely don't want to lose your progress_), the model will _also_ be saved there in a unique folder.\n",
    "\n",
    "#### **Below I copy and paste the documentation of _aitextgen_ to set the `train()` parameters for GPT2:**\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. _aitextgen_ will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. **Only works on a T4 or V100 GPU.**\n",
    "\n",
    "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
    "\n",
    "- **`learning_rate`**: Learning rate of the model training.\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. (if using `fp16`, you can increase the batch size more safely)"
   ],
   "metadata": {
    "id": "LdpZQXknFNY3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 8\n",
    "\n",
    "ai.train(file_name,\n",
    "         line_by_line=False,\n",
    "         from_cache=False,\n",
    "         num_steps=3000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=True,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=True,\n",
    "         batch_size=1, \n",
    "         )"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560,
     "referenced_widgets": [
      "0b7e18fdcc8541438e589c15ed072129",
      "bb419f20acb54b43ab9c8ac544344b01",
      "dfa15f9c64dd4b0db53d40508f8bf40c",
      "38817132892f417c94435753927180dc",
      "f92d039fe5c14a42980c5ecd6b3c982d",
      "8a6adae3600342b2bbdd165fdc8fb8e6",
      "46c820b22c9d48a6988bc8fea63fa4b3",
      "206abe185b9d4bf481d5b3dbcb19fd4b",
      "cdce8daf59fb49d1a4a8c344b9692fba",
      "d8e38eabf77c423da125f74389763c54",
      "02fa3dae7d9e4ae2bfb095880cebf072",
      "4bc50f008b1c4d7080c9ad74b1aac9db",
      "afcbc83d3c2e4523a7b4e073e612d7cc",
      "6410ed18da324282a06a75d4f1e44e9a",
      "afd77c369afb4fe295aebdedc93e63c1",
      "205b0ec9dc5746a9910a06ff3e506399"
     ]
    },
    "executionInfo": {
     "elapsed": 871926,
     "status": "ok",
     "timestamp": 1628847286248,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "6d7c68de-56e6-4cdc-cdb2-65e419358f6e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finetuning complete!\n",
    "\n",
    "When the process is finished, you will find a new `trained model` folder in the Colaboratory files to the **left** of your screen (same place where you had uploaded the training dataset). \n",
    "\n",
    "The folder is quite heavy and contains two files (`pytorch_model.bin` and `config.json`). To use it within the _Karl Marx's Press Review_ project, **download its content and copy it** <u>as it is</u> into the <u>two subfolders</u> `trained_model` that may be found in:\n",
    "- `marxist_press_review/article_collector/` and \n",
    "- `marxist_press_review/press_review_app/`\n",
    "\n",
    "This will allow the modules contained in these folders to run.\n",
    "\n",
    "But before doing that, and in case you were using this code for finetuning a GPT2 on **your own dataset**, I strongly advice to run the following cells as a test for what you have done. <u>Bad results may lead you to rework your dataset</u>, or to change the parameters in `cell 8`.\n"
   ],
   "metadata": {
    "id": "qQJgV_b4bmzd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell will allow you to load the retrained model + metadata necessary to generate text."
   ],
   "metadata": {
    "id": "RTa6zf3e_9gV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 9\n",
    "\n",
    "ai = aitextgen(model_folder=\"trained_model\", to_gpu=True)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2552,
     "status": "ok",
     "timestamp": 1628847994918,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "-fxL77nvAMAX",
    "outputId": "8388fb7b-706c-4163-d26a-19dc08e42e46"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Text From The Trained Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text.\n",
    "\n",
    "**If you just trained a model**, you'll get much faster training performance if you reload the model; the next cell will reload the model you just trained from the `trained_model` folder."
   ],
   "metadata": {
    "id": "ClJwpF_ACONp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 10\n",
    "\n",
    "ai = aitextgen(model_folder=\"trained_model\", to_gpu=True)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16721,
     "status": "ok",
     "timestamp": 1625682363176,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "mSvHhTuHJc-Q",
    "outputId": "3c8629bc-a436-4043-8f5b-5e1e14482e81"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check out the [_aitextgen_ documentation](https://docs.aitextgen.io/generate/) for the available options when generating text.  Here, for mere testing purpose, I have chosen to generate multiple texts at a time (this can be done by specifing the **`n`** parameter). You can pass a **`batch_size`** to generate multiple samples in parallel (this parameter can be set up to 50 in Colaboratory). If provided, the **`prompt`** parameter allows to force the beginning of the sentence to a certain string.\n",
    "\n",
    "Other optional-but-helpful parameters for `ai.generate()`, taken from the _aitextgen_ documentation:\n",
    "\n",
    "*  **`min length`**: The minimum length of the generated text: if the text is shorter than this value after cleanup, aitextgen will generate another one.\n",
    "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2 and 2048 with GPT Neo)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
   ],
   "metadata": {
    "id": "oF4-PqF0Fl7R"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#cell 11\n",
    "\n",
    "ai.generate(n=5,\n",
    "            batch_size=3,\n",
    "            prompt=\"Wages are growing\",\n",
    "            min_length=10,\n",
    "            max_length=100,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "            )"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1958,
     "status": "ok",
     "timestamp": 1628848600326,
     "user": {
      "displayName": "Francesco Mari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghtzn7DS8bhEwyA6KTmh7gGotlCfcF_BHupBqHfDtY=s64",
      "userId": "14083574958184313057"
     },
     "user_tz": -120
    },
    "id": "8DKMc0fiej4N",
    "outputId": "0e4d42a4-8ee8-48ec-ba4e-0b81787f5f25"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **AND THAT'S IT!** \n",
    "Below I paste the licence included in the original Notebook by Max Woolf from which I have adapted my code.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **MIT License**\n",
    "\n",
    "Copyright (c) 2020-2021 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ],
   "metadata": {
    "id": "wmTXWNUygS5E"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text-Generating_GPT-2 _Fine-Tuner_on_Colab_GPU",
   "provenance": [
    {
     "file_id": "15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD",
     "timestamp": 1625502365469
    },
    {
     "file_id": "1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce",
     "timestamp": 1589676386656
    },
    {
     "file_id": "1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK",
     "timestamp": 1555602712120
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02fa3dae7d9e4ae2bfb095880cebf072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Loss: 0.132 — Avg: 0.131 — GPU Mem: 6230 MB: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6410ed18da324282a06a75d4f1e44e9a",
      "max": 3000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afcbc83d3c2e4523a7b4e073e612d7cc",
      "value": 3000
     }
    },
    "0b7e18fdcc8541438e589c15ed072129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfa15f9c64dd4b0db53d40508f8bf40c",
       "IPY_MODEL_38817132892f417c94435753927180dc"
      ],
      "layout": "IPY_MODEL_bb419f20acb54b43ab9c8ac544344b01"
     }
    },
    "205b0ec9dc5746a9910a06ff3e506399": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "206abe185b9d4bf481d5b3dbcb19fd4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38817132892f417c94435753927180dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_206abe185b9d4bf481d5b3dbcb19fd4b",
      "placeholder": "​",
      "style": "IPY_MODEL_46c820b22c9d48a6988bc8fea63fa4b3",
      "value": " 1/1 [00:00&lt;00:00,  2.43it/s]"
     }
    },
    "46c820b22c9d48a6988bc8fea63fa4b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bc50f008b1c4d7080c9ad74b1aac9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_205b0ec9dc5746a9910a06ff3e506399",
      "placeholder": "​",
      "style": "IPY_MODEL_afd77c369afb4fe295aebdedc93e63c1",
      "value": " 3000/3000 [14:18&lt;00:00,  3.50it/s]"
     }
    },
    "6410ed18da324282a06a75d4f1e44e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a6adae3600342b2bbdd165fdc8fb8e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afcbc83d3c2e4523a7b4e073e612d7cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "afd77c369afb4fe295aebdedc93e63c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb419f20acb54b43ab9c8ac544344b01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "cdce8daf59fb49d1a4a8c344b9692fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02fa3dae7d9e4ae2bfb095880cebf072",
       "IPY_MODEL_4bc50f008b1c4d7080c9ad74b1aac9db"
      ],
      "layout": "IPY_MODEL_d8e38eabf77c423da125f74389763c54"
     }
    },
    "d8e38eabf77c423da125f74389763c54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "dfa15f9c64dd4b0db53d40508f8bf40c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a6adae3600342b2bbdd165fdc8fb8e6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f92d039fe5c14a42980c5ecd6b3c982d",
      "value": 1
     }
    },
    "f92d039fe5c14a42980c5ecd6b3c982d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}